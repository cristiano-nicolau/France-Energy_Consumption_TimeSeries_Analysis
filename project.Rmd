# Time Series Analysis of French Electricity Consumption: 2024-2025 Project

## 1. Introduction
This report details the analysis of monthly electricity consumption in France from January 2008 to March 2025. The primary objective is to develop a robust time series model capable of accurately forecasting future consumption. 

The methodology follows the Box-Jenkins approach for building a Seasonal Autoregressive Integrated Moving Average (SARIMA) model.  The process involves several key stages:

1. Exploratory Data Analysis: Initial visualization and decomposition of the data to understand its underlying structure, including trend and seasonality.
2. Data Transformation: Applying necessary transformations to stabilize the variance and stationarize the series.
3. Model Identification, Estimation, and Diagnostics: Proposing candidate SARIMA models based on the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF), estimating model parameters, and performing rigorous diagnostic checks on the model's residuals. 
4. Forecasting and Accuracy Evaluation: Generating forecasts on a hold-out test set and evaluating their accuracy using standard metrics. 

The dataset will be split into a training set for model building and a test set for forecast validation, as recommended. 

## 2. Data and Exploratory Analysis

### Data Loading and Preparation
First, we load the necessary R libraries and the dataset. The data represents the monthly electricity available to the internal market in France, measured in Gigawatt-hours (GWh).

```{r}
# install.packages(c("forecast", "urca", "lmtest", "tseries", "ggplot2"))
library(forecast)
library(urca)
library(lmtest)
library(tseries)
library(ggplot2)

# Load the data
dados <- read.csv("data/data2.csv")

# Create a time series object
# The data is monthly (frequency=12) and starts in January 2008.
ts_data <- ts(dados$OBS_VALUE, start = c(2008, 1), frequency = 12)
names(dados)
head(dados)
```

### Exploratory Analysis
We begin by plotting the time series to visually inspect its components.

```{r}
autoplot(ts_data,
         ylab = "Consumption (GWh)",
         xlab = "Year",
         main = "Monthly Electricity Consumption in France (2008-2025)")
```
The plot reveals two key characteristics:

1. Strong Seasonality: There is a clear and repeating annual pattern, with consumption peaking in the winter months and reaching a low in the summer.
2. Trend: There appears to be a slight downward trend in consumption over the years, particularly after 2010.
To better visualize these components, we decompose the series.


```{r}
# Decompose the series to show trend, seasonality, and remainder
decomposed <- decompose(ts_data, type = "multiplicative")
autoplot(decomposed)
```
The decomposition confirms the strong seasonal pattern and a visible, though somewhat noisy, trend.

### Data Splitting
To properly evaluate our model's forecasting ability, we split the data into a training set (80% of the data) for model fitting and a test set (the remaining 20%) for validation.

```{r}
# Split data: 80% for training, 20% for testing
n <- length(ts_data)
train_size <- floor(0.8 * n)
ts_train <- window(ts_data, end = time(ts_data)[train_size])
ts_test <- window(ts_data, start = time(ts_data)[train_size + 1])

cat("Training set length:", length(ts_train), "observations\n")
cat("Test set length:", length(ts_test), "observations\n")
```

## 3. Model Proposal and Diagnostics
### Stationarity Assessment
SARIMA models require the data to be stationary (i.e., its mean, variance, and autocorrelation are constant over time). The original training data is not stationary due to the trend and seasonality. We can confirm this with statistical tests.

- Augmented Dickey-Fuller (ADF) Test: Null hypothesis $$H_0$$ is that the series is non-stationary.
- KPSS Test: Null hypothesis $$H_0$$ is that the series is is stationary.

```{r}
# ADF test on the training data
adf.test(ts_train)

# KPSS test on the training data
kpss.test(ts_train)
```
The ADF test's high p-value (> 0.05) means we cannot reject  $$H_0$$ , suggesting non-stationarity. 
The KPSS test's low p-value (< 0.05) leads us to reject  $$H_0$$ , also indicating non-stationarity.

### Achieving Stationarity through Differencing
To make the series stationary, we apply differencing. Given the strong 12-month seasonality, we start with seasonal differencing (lag=12).
```{r}
# Apply seasonal differencing (D=1)
ts_seasonal_diff <- diff(ts_train, lag = 12)
autoplot(ts_seasonal_diff, main = "Seasonally Differenced Series")
```
The seasonal pattern is gone, but a trend might still be present. We now apply a regular first difference to remove any remaining trend.

```{r}
# Apply regular differencing to the seasonally differenced series (d=1)
ts_stationary <- diff(ts_seasonal_diff, differences = 1)
autoplot(ts_stationary, main = "Seasonally and Regularly Differenced Series")
```
This series appears stationary. Let's re-run the tests to confirm.

```{r}
adf.test(ts_stationary)
kpss.test(ts_stationary)
```

After applying seasonal differencing (lag = 12) and a first regular difference, we re-evaluated the series for stationarity. The Augmented Dickey-Fuller (ADF) test strongly rejected the null hypothesis of non-stationarity (ADF = â€“8.3772, p < 0.01), and the KPSS test failed to reject the null of stationarity (KPSS = 0.033, p > 0.1). These results confirm that the differenced series is stationary. Consequently, we proceed with SARIMA modeling using (d = 1, D = 1, s = 12).

### Model Identification using ACF and PACF
We now analyze the ACF and PACF plots of the stationary series to identify the orders of the AR and MA components (p, q, P, Q). 
```{r}
# ACF and PACF of the stationary series
ggtsdisplay(ts_stationary, main="ACF/PACF of Stationary Series")
```
- Seasonal Order (P, Q): At the seasonal lag 12, the ACF has a significant negative spike, and the PACF cuts off afterward. This suggests a seasonal MA(1) model, so we set Q=1 and P=0.
- Non-Seasonal Order (p, q): In the non-seasonal lags, the ACF has a significant spike at lag 1 and the PACF has a significant spike at lag 1. This could suggest either an AR(1) or MA(1) model.

Based on this, a good candidate model is SARIMA(p,1,q)(0,1,1)[12]. We'll let auto.arima() find the optimal p and q values.


### Model Estimation and Diagnostics
We use the auto.arima() function to automatically select the best mode
#### Auto Arima

```{r}
# Fit model using auto.arima on the training data
auto_fit <- auto.arima(ts_train, stepwise = FALSE, approximation = FALSE)
summary(auto_fit)
```
auto.arima selected a SARIMA(2,0,0)(0,1,2)[12] model. 
Next, we perform diagnostic checks on the model's residuals to ensure they behave like white noise (i.e., are random and uncorrelated).

```{r}
# Perform residual diagnostics
checkresiduals(auto_fit)
```


The diagnostic plots show:

- The residuals plot shows no obvious patterns, appearing random around a mean of zero.
- The ACF plot of residuals have only one significant spikes
- The Ljung-Box test has a large p-value (0.35), meaning we cannot reject the null hypothesis that the residuals are independently distributed.
The model successfully passes the diagnostic checks.

## 4. Future Observations Forecast
We now use our final model, to forecast the next 41 observations.


```{r}
# Generate forecasts
forecast_horizon <- length(ts_test)
sarima_forecast <- forecast(auto_fit, h = forecast_horizon)

# Plot the forecast against the actual values
autoplot(sarima_forecast) +
  autolayer(ts_test, series = "Actual Data") +
  labs(title = "SARIMA Forecast vs. Actual Data",
       x = "Year", y = "Consumption (GWh)")
```
### Forecast Accuracy
Finally, we compare the forecasts to the held-out test data to evaluate the model's accuracy.

```{r}
# Calculate accuracy metrics by comparing forecast to test set
accuracy(sarima_forecast, ts_test)
```
The accuracy metrics, particularly the Mean Absolute Percentage Error (MAPE) on the test set (4.37%), indicate that the model's forecasts are, on average, within approximately 4,5% of the actual values. This demonstrates a high level of accuracy. The Root Mean Squared Error (RMSE) gives a measure of the typical error magnitude in GWh.

## 6. Alternative SARIMA MODEL: SARIMA(1,1,1)(0,1,1)[12]
```{r}
manual_fit <- Arima(ts_train, order = c(1,1,1), 
                    seasonal = list(order = c(0,1,1), period = 12),
                    include.drift = FALSE)  # usually better to exclude drift when d=1
summary(manual_fit)
```
```{r}
checkresiduals(manual_fit)

```


```{r}
# Forecast with manual SARIMA
sarima_manual_forecast <- forecast(manual_fit, h = length(ts_test))

# Plot forecasts
autoplot(sarima_manual_forecast) +
  autolayer(ts_test, series = "Actual") +
  labs(title = "SARIMA(1,1,1)(0,1,1)[12] Forecast vs. Actual",
       x = "Year", y = "Consumption (GWh)")

# Forecast accuracy
accuracy(sarima_manual_forecast, ts_test)

```
## 7. Alternative Model: STL

```{r}
stlm_fit <- stlm(ts_train, s.window = "periodic", method = "arima")
summary(stlm_fit)
checkresiduals(stlm_fit)

```

```{r}
stlm_forecast <- forecast(stlm_fit, h = length(ts_test))
accuracy(stlm_forecast, ts_test)
```


## 8. Alternative Model: Exponential Smoothing (ETS)
We will now fit an ETS model to the training data. The ets() function in the forecast package automatically selects the best model by testing different combinations of error, trend, and seasonality components (additive, multiplicative, damped, etc.) and choosing the one with the lowest AICc.


```{r}
# Fit an ETS model to the training data
ets_fit <- ets(ts_train)
summary(ets_fit)
```
The function selected an ETS(M,Ad,M) model. This notation stands for:

- Error: Multiplicative (M)
- Trend: Damped Additive (Ad)
- Seasonality: Multiplicative (M)
This choice is sensible, as it acknowledges the multiplicative nature of the seasonality seen in the initial plots, while incorporating a trend component that dampens over time.

Next, we perform diagnostic checks on the ETS model's residuals.

```{r}
# Perform residual diagnostics for the ETS model
checkresiduals(ets_fit)
```



```{r}
# Generate forecasts using the fitted ETS model
ets_forecast <- forecast(ets_fit, h = length(ts_test))

# Plot forecasts
autoplot(ets_forecast) +
  autolayer(ts_test, series = "Actual") +
  labs(title = "ETS Model Forecast vs. Actual",
       x = "Year", y = "Consumption (GWh)")


# Calculate accuracy metrics
accuracy(ets_forecast, ts_test)
```

## 9. Compare Models

```{r}
library(knitr)
results <- rbind(
  SARIMA_auto = accuracy(sarima_forecast, ts_test)[2, c("RMSE", "MAE", "MAPE", "Theil's U")],
  SARIMA_manual = accuracy(sarima_manual_forecast, ts_test)[2, c("RMSE", "MAE", "MAPE", "Theil's U")],
  ETS = accuracy(ets_forecast, ts_test)[2, c("RMSE", "MAE", "MAPE", "Theil's U")],
  STLM_ARIMA = accuracy(stlm_forecast, ts_test)[2, c("RMSE", "MAE", "MAPE", "Theil's U")]
)
kable(round(results, 2), caption = "Forecast Accuracy Comparison on Test Set")

```
```{r}
autoplot(ts_test, series = "Actual") +
  autolayer(sarima_forecast$mean, series = "SARIMA Auto", PI = FALSE) +
  autolayer(sarima_manual_forecast$mean, series = "SARIMA Manual", PI = FALSE) +
  autolayer(ets_forecast$mean, series = "ETS", PI = FALSE) +
  autolayer(stlm_forecast$mean, series = "STLM+ARIMA", PI = FALSE) +
  labs(title = "Model Forecasts vs Actual Data", y = "GWh", x = "Time") +
  guides(colour = guide_legend(title = "Forecasts")) +
  theme_minimal()

```

